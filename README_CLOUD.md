# FloydHub

Config:
- [.floydexpt](.floydexpt) - generated by `floyd login`  
- [floyd.yml](floyd.yml) - generated by `floyd init`
- [floyd_requirements.txt](floyd_requirements.txt) - runs `pip install`
- [.floydignore](.floydignore) - 100Mb filesize upload

Execute:
```
floyd init jamesmcguigan/randomseedsearch
floyd status
floyd stop    $ID
floyd delete  $ID
```

```bash
floyd run -m "random_seed_search: 0:2000" \
    "python3 ./src/random/random_seed_search.py --min_seed=0    --increment=1000 --method=numpy &" \
    "python3 ./src/random/random_seed_search.py --min_seed=1000 --increment=1000 --method=numpy &" \
    "jobs; wait %2 %3; exit"       
```
```bash
 START=10000000
   END=1000000000
   INC=10000000
METHOD='numpy'   
for i in `seq 0 2 100`; do
    N1=`echo "$START + $INC * ($i    )" | bc`
    N2=`echo "$START + $INC * ($i + 1)" | bc`
    N3=`echo "$START + $INC * ($i + 2)" | bc`    
    if [[ $N1 -ge $END ]]; then break; fi; 
    floyd run -m "random_seed_search - $METHOD - $N1:$N3" \
        "python3 ./src/random/random_seed_search.py --min_seed=$N1 --increment=$INC --method=$METHOD &" \
        "python3 ./src/random/random_seed_search.py --min_seed=$N2 --increment=$INC --method=$METHOD &" \
        "jobs; wait %2 %3; exit;"       
done
```
- https://www.floydhub.com/jamesmcguigan/projects/randomseedsearch/

View Logs
```
# This works upto until you have more than 25 job ids
floyd status | grep random_seed_search | grep -v failed | grep numpy | awk '{ print $1 }' |      
    xargs -L1 -P0 -t timeout 5 floyd logs 2> /dev/null |      
    grep Found | sed 's/^.*-//' | sort -n -k5 | uniq


# floyd status only returns the last 25 jobs, so downloading 99 logs requires a bit more creativity
JOBS_NP=$(
    seq 0 100 | xargs -I{} echo jamesmcguigan/projects/randomseedsearch/{} |
        xargs -L1 -P0 -t floyd status 2> /dev/null | grep numpy | grep -v failed | awk '{ print $1 }' 
);
JOBS_TF=$(
    seq 0 100 | xargs -I{} echo jamesmcguigan/projects/randomseedsearch/{} |
        xargs -L1 -P0 -t floyd status 2> /dev/null | grep tf | grep -v failed | awk '{ print $1 }' 
);
echo $JOBS_NP | xargs -d' ' -L1 -P0  timeout 60 floyd logs 2> /dev/null |      
    grep Found | sed 's/^.*-//' | sort -n -k9 | uniq    

echo $JOBS_TF | xargs -d' ' -L1 -P0 timeout 60 floyd logs 2> /dev/null |      
    grep Found | sed 's/^.*-//' | sort -n -k9 | uniq    


 
```


# Gradient Paperspace

NOTE: Paperspace batch jobs can take 20+ minutes to run

- Docs: https://paperspace.github.io/paperspace-node/jobs.html
- Containers: https://docs.paperspace.com/gradient/notebooks/notebook-containers
    - BROKEN: tensorflow/serving:latest-gpu
    - WORKS:  jupyter/datascience-notebook
    - SLOW?:  ufoym/deepo:all-py36-jupyter 
    - UNTESTED: tensorflow/tensorflow:2.0.0a0-gpu-py3-jupyter
 
- Jobs: https://www.paperspace.com/console/projects/prw0az0p6/experiments
```
gradient jobs list
gradient projects list
```


```
time -p \
gradient experiments run singlenode \
    --command 'ls -la' \
    --name 'ls -la' \
    --machineType G1  \
    --container ufoym/deepo:all-py36-jupyter \
    --projectId prw0az0p6 \
    --workspace https://github.com/JamesMcGuigan/kaggle-digit-recognizer.git
```
- jupyter/datascience-notebook = 22min


````
time -p \
gradient experiments run singlenode \
    --command 'pip install -r requirements.in; python3 src/random/random_seed_search.py --min_seed 0 --increment 10000' \
    --name                                    'python3 src/random/random_seed_search.py --min_seed 0 --increment 10000' \
    --container tensorflow/tensorflow:2.0.0a0-gpu-py3-jupyter \
    --machineType G1  \
    --projectId prw0az0p6 \
    --workspace https://github.com/JamesMcGuigan/kaggle-digit-recognizer.git
```
